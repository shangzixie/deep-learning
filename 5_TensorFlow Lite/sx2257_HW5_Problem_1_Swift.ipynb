{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cl3895_HW5_Problem_1_Swift.ipynb","provenance":[{"file_id":"1wwXtn0PmZuOb90gaxlwvxmJ-pfv3bzWb","timestamp":1576882744861},{"file_id":"https://github.com/tensorflow/swift/blob/master/notebooks/blank_swift.ipynb","timestamp":1576293401485}],"collapsed_sections":[]},"kernelspec":{"name":"swift","display_name":"Swift"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"szETcH3uamYj","colab_type":"code","colab":{}},"source":["\n","import TensorFlow\n","import Python\n","import Datasets\n","import ImageClassificationModels\n","PythonLibrary.useVersion(3) // Use Python 3.x\n","// Import some Python libraries\n","let plt = Python.import(\"matplotlib.pyplot\")\n","let time = Python.import(\"time\")\n","\n","func downloadCIFAR10IfNotPresent(to directory: String = \".\") {\n","  let subprocess = Python.import(\"subprocess\")\n","  let path = Python.import(\"os.path\")\n","  let filepath = \"\\(directory)/cifar-10-batches-py\"\n","  let isdir = Bool(path.isdir(filepath))!\n","  if !isdir {\n","    print(\"Downloading CIFAR data...\")\n","    let command = \"wget -nv -O- https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz | tar xzf - -C \\(directory)\"\n","    subprocess.call(command, shell: true)\n","  }\n","}\n","\n","struct Example: TensorGroup {\n","  var label: Tensor<Int32>\n","  var data: Tensor<Float>\n","}\n","\n","// Each CIFAR data file is provided as a Python pickle of NumPy arrays\n","func loadCIFARFile(named name: String, in directory: String = \".\") -> Example {\n","  downloadCIFAR10IfNotPresent(to: directory)\n","  let np = Python.import(\"numpy\")\n","  let pickle = Python.import(\"pickle\")\n","  let path = \"\\(directory)/cifar-10-batches-py/\\(name)\"\n","  let f = Python.open(path, \"rb\")\n","  let res = pickle.load(f, encoding: \"bytes\")\n","\n","  let bytes = res[Python.bytes(\"data\", encoding: \"utf8\")]\n","  let labels = res[Python.bytes(\"labels\", encoding: \"utf8\")]\n","\n","  let labelTensor = Tensor<Int64>(numpy: np.array(labels))!\n","  let images = Tensor<UInt8>(numpy: bytes)!\n","  let imageCount = images.shape[0]\n","\n","  // reshape and transpose from the provided N(CHW) to TF default NHWC\n","  let imageTensor = Tensor<Float>(images\n","      .reshaped(to: [imageCount, 3, 32, 32])\n","      .transposed(withPermutations: [0, 2, 3, 1]))\n","\n","  let mean = Tensor<Float>([0.485, 0.456, 0.406])\n","  let std  = Tensor<Float>([0.229, 0.224, 0.225])\n","  let imagesNormalized = ((imageTensor / 255.0) - mean) / std\n","\n","  return Example(label: Tensor<Int32>(labelTensor), data: imagesNormalized)\n","}\n","\n","func loadCIFARTrainingFiles() -> Example {\n","  let data = (1..<6).map { loadCIFARFile(named: \"data_batch_\\($0)\") }\n","  return Example(\n","    label: Raw.concat(concatDim: Tensor<Int32>(0), data.map { $0.label }),\n","    data: Raw.concat(concatDim: Tensor<Int32>(0), data.map { $0.data })\n","  )\n","}\n","\n","func loadCIFARTestFile() -> Example {\n","  return loadCIFARFile(named: \"test_batch\")\n","}\n","\n","func loadCIFAR10() -> (\n","  training: Dataset<Example>, test: Dataset<Example>) {\n","    let trainingDataset = Dataset<Example>(elements: loadCIFARTrainingFiles())\n","    let testDataset = Dataset<Example>(elements: loadCIFARTestFile())\n","    return (training: trainingDataset, test: testDataset)\n","}\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZRlD4utdPuX","colab_type":"code","outputId":"2c7cd3fb-33ba-4b5b-e0c2-b5ee5e8ce79c","executionInfo":{"status":"ok","timestamp":1576295205299,"user_tz":300,"elapsed":146570,"user":{"displayName":"Chiqu Li","photoUrl":"","userId":"11343758097451996406"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["\n","let batchSize = 100\n","// load the dataset\n","let dataset = loadCIFAR10()\n","let testBatches = dataset.test.batched(batchSize)\n","\n","\n","struct KerasModel: Layer {\n","    typealias Input = Tensor<Float>\n","    typealias Output = Tensor<Float>\n","\n","    var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 32), padding: .same, activation: relu)\n","    var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 32), activation: relu)\n","    var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n","    var dropout1 = Dropout<Float>(probability: 0.25)\n","    var conv2a = Conv2D<Float>(filterShape: (3, 3, 32, 64), padding: .same, activation: relu)\n","    var conv2b = Conv2D<Float>(filterShape: (3, 3, 64, 64), activation: relu)\n","    var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n","    var dropout2 = Dropout<Float>(probability: 0.25)\n","    var flatten = Flatten<Float>()\n","    var dense1 = Dense<Float>(inputSize: 64 * 6 * 6, outputSize: 512, activation: relu)\n","    var dropout3 = Dropout<Float>(probability: 0.5)\n","    var dense2 = Dense<Float>(inputSize: 512, outputSize: 10, activation: identity)\n","\n","    @differentiable\n","    func callAsFunction(_ input: Input) -> Output {\n","        let conv1 = input.sequenced(through: conv1a, conv1b, pool1, dropout1)\n","        let conv2 = conv1.sequenced(through: conv2a, conv2b, pool2, dropout2)\n","        return conv2.sequenced(through: flatten, dense1, dropout3, dense2)\n","    }\n","}\n","var model = KerasModel()\n","\n","// the classic ImageNet optimizer setting diverges on CIFAR-10\n","// let optimizer = SGD(for: model, learningRate: 0.1, momentum: 0.9)\n","let optimizer = SGD(for: model, learningRate: 0.001)\n","\n","print(\"Starting training...\")\n","print(dataset.training)\n","for epoch in 1...10 {\n","    Context.local.learningPhase = .training\n","    var trainingLossSum: Float = 0\n","    var trainingBatchCount = 0\n","    let trainingShuffled = dataset.training.shuffled(sampleCount:50000,randomSeed: Int64(epoch))\n","    for batch in trainingShuffled.batched(batchSize) {\n","        let (labels, images) = (batch.label, batch.data)\n","        let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n","            let logits = model(images)\n","            return softmaxCrossEntropy(logits: logits, labels: labels)\n","        }\n","        trainingLossSum += loss.scalarized()\n","        trainingBatchCount += 1\n","        optimizer.update(&model, along: gradients)\n","    }\n","\n","    Context.local.learningPhase = .inference\n","    var testLossSum: Float = 0\n","    var testBatchCount = 0\n","    var correctGuessCount = 0\n","    var totalGuessCount = 0\n","    for batch in testBatches {\n","        let (labels, images) = (batch.label, batch.data)\n","        let logits = model(images)\n","        testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()\n","        testBatchCount += 1\n","\n","        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n","        correctGuessCount = correctGuessCount\n","            + Int(\n","                Tensor<Int32>(correctPredictions).sum().scalarized())\n","        totalGuessCount = totalGuessCount + batchSize\n","    }\n","\n","    let accuracy = Float(correctGuessCount) / Float(totalGuessCount)\n","    print(\n","        \"\"\"\n","        [Epoch \\(epoch)] \\\n","        Accuracy: \\(correctGuessCount)/\\(totalGuessCount) (\\(accuracy)) \\\n","        Loss: \\(testLossSum / Float(testBatchCount))\n","        \"\"\"\n","    )\n","}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting training...\r\n","Dataset<Example>(_handle: TensorFlow.VariantHandle(handle: TensorFlow.TFETensorHandle))\n","[Epoch 1] Accuracy: 1941/10000 (0.1941) Loss: 2.2519734\n","[Epoch 2] Accuracy: 2461/10000 (0.2461) Loss: 2.187424\n","[Epoch 3] Accuracy: 2708/10000 (0.2708) Loss: 2.1010232\n","[Epoch 4] Accuracy: 2810/10000 (0.281) Loss: 2.042903\n","[Epoch 5] Accuracy: 2919/10000 (0.2919) Loss: 2.0029104\n","[Epoch 6] Accuracy: 2999/10000 (0.2999) Loss: 1.9740992\n","[Epoch 7] Accuracy: 3164/10000 (0.3164) Loss: 1.9436333\n","[Epoch 8] Accuracy: 3257/10000 (0.3257) Loss: 1.9116424\n","[Epoch 9] Accuracy: 3377/10000 (0.3377) Loss: 1.8783388\n","[Epoch 10] Accuracy: 3481/10000 (0.3481) Loss: 1.8418988\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bDcA7IM_awW-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}